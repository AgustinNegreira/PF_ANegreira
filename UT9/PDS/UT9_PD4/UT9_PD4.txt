UT9_PD4

Ejercicio 1:  
En la investigación sobre incrementos para ShellSort, se destacan múltiples secuencias propuestas a lo largo del tiempo. La secuencia original de Donald Shell (n/2, n/4, ..., 1) es fácil de implementar, pero no es la más eficiente. Subsecuencias más modernas como las de Hibbard (2^k - 1) o Sedgewick (que mezcla potencias de 2 y 3) ofrecen un mejor rendimiento práctico, reduciendo el número de comparaciones. Más recientemente, la secuencia de Pratt, basada en números libres de factores primos mayores que 2 y 3, ha mostrado ser muy eficiente aunque costosa en términos de memoria. También se estudian secuencias adaptadas al hardware, como la de Tokuda, que balancean complejidad y velocidad en arreglos grandes. Estas secuencias varían en rendimiento dependiendo del tamaño del conjunto de datos y la distribución inicial, pero generalmente se observa una mejora considerable frente al esquema original. Pruebas en implementaciones de clase muestran que secuencias como las de Sedgewick y Tokuda superan a las de Shell en arreglos grandes y aleatorios.

Ejercicio 2: 
Para QuickSort, las funciones de pivote tienen un impacto crítico en su eficiencia. El pivote al azar, usado frecuentemente, minimiza el riesgo del peor caso (O(n^2)), aunque su costo adicional por generación de números aleatorios puede ser significativo. Otro enfoque es el pivote mediana de tres, que combina la mediana de los valores inicial, medio y final, logrando dividir los datos de manera más uniforme en promedio. Las implementaciones modernas en lenguajes como Java y Python combinan QuickSort con técnicas híbridas; por ejemplo, el "Timsort" en Python utiliza QuickSort para pequeñas particiones, pero recurre a MergeSort o inserción para manejar subarreglos específicos. En Java, QuickSort usa pivotes aleatorios optimizados para evitar el peor caso en arreglos ya ordenados o casi ordenados. En pruebas con implementaciones de clase, el pivote mediana de tres mostró menor profundidad de recursión y mejor rendimiento general comparado con un pivote fijo.

Ejercicio 3: 
Para determinar si dos conjuntos son disjuntos, un enfoque eficiente utiliza conceptos de clasificación. Primero, ordenar el conjunto más grande (n, suponiendo que n > m) con un algoritmo de complejidad O(n log n). Luego, para cada elemento del conjunto más pequeño (m), realizar una búsqueda binaria en el conjunto más grande, con un costo O(log n) por elemento, resultando en un tiempo total de O(m log n). Este enfoque es particularmente eficiente cuando m es mucho menor que n, pues evita comparar cada par de elementos directamente, como ocurre en un algoritmo ingenuo de O(m * n). El peor caso se presenta cuando todos los elementos de m están en n, pero incluso en ese caso, la complejidad es manejable para conjuntos grandes. Este algoritmo aprovecha la estructura ordenada para maximizar la eficiencia.